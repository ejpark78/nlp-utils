#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from os import getenv

from crawler.web_news.web_news import WebNewsCrawler


description = """웹 뉴스 크롤러"""

epilog = """\
usage example:

"""


class WebNewsCrawlerBatch(object):

    def __init__(self):
        super().__init__()

    def batch(self) -> None:
        params, default_params = self.init_arguments()

        WebNewsCrawler(params=params, default_params=default_params).batch()
        return

    @staticmethod
    def init_arguments() -> (dict, dict):
        import argparse
        import textwrap

        global description, epilog

        parser = argparse.ArgumentParser(
            description=textwrap.dedent(description),
            epilog=textwrap.dedent(epilog),
            formatter_class=argparse.RawDescriptionHelpFormatter
        )

        # crawler options: flow-control
        parser.add_argument('--list', action='store_true', default=False, help='기사 목록 크롤링')
        parser.add_argument('--contents', action='store_true', default=False, help='기사 본문 크롤링')

        # essential
        parser.add_argument('--config', default=None, type=str, help='설정 파일 정보')

        # config overwrite
        parser.add_argument('--job-name', default='', type=str, help='잡 이름, 없는 경우 전체')
        parser.add_argument('--sub-category', default='', type=str, help='하위 카테고리')

        parser.add_argument('--date-range', default=None, type=str, help='date 날짜 범위: 2000-01-01~2019-04-10')
        parser.add_argument('--date-step', default=-1, type=int, help='date step')

        parser.add_argument('--page-range', default=None, type=str, help='page 범위: 1~100')
        parser.add_argument('--page-step', default=1, type=int, help='page step')

        parser.add_argument('--sleep', default=10, type=float, help='sleep time')
        parser.add_argument('--request-timeout', default=320, type=float, help='request timeout')

        # optional
        parser.add_argument('--overwrite', action='store_true', default=False, help='(optional) 덮어쓰기')

        parser.add_argument('--mapping', default=None, type=str, help='(optional) 인덱스 맵핑 파일 정보')

        parser.add_argument('--verbose', default=-1, type=int, help='(optional) verbose 모드: 1=INFO')

        return vars(parser.parse_args()), vars(parser.parse_args([]))


if __name__ == '__main__':
    WebNewsCrawlerBatch().batch()
