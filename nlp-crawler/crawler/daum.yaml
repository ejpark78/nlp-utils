---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-culture
  labels:
    app: crawler
spec:
  schedule: "0,30 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_CULTURE)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "culture"
              ]

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-economy
  labels:
    app: crawler
spec:
  schedule: "5,35 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_ECONOMY)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "economy"
              ]

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-international
  labels:
    app: crawler
spec:
  schedule: "10,40 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_INTERNATIONAL)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "international"
              ]

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-it
  labels:
    app: crawler
spec:
  schedule: "15,45 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_IT)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "it"
              ]

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-opinion
  labels:
    app: crawler
spec:
  schedule: "20,50 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_OPINION)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "opinion"
              ]

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-politics
  labels:
    app: crawler
spec:
  schedule: "25,55 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_POLITICS)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "politics"
              ]

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-society
  labels:
    app: crawler
spec:
  schedule: "0,30 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_SOCIETY)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "society"
              ]

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daum-sports
  labels:
    app: crawler
spec:
  schedule: "5,35 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 0
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          hostAliases:
            - ip: "172.20.93.112"
              hostnames:
                - "corpus.ncsoft.com"
          imagePullSecrets:
            - name: registry
          containers:
            - name: default
              image: registry.nlp-utils/crawler:latest
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 100m
                  memory: 100Mi
                limits:
                  cpu: 200m
                  memory: 200Mi
              workingDir: /usr/local/app
              env:
                - name: ELASTIC_SEARCH_INDEX
                  value: $(INDEX_SPORTS)
                - name: ELASTIC_SEARCH_AUTH
                  valueFrom:
                    secretKeyRef:
                      name: elasticsearch-auth
                      key: http_auth
              envFrom:
                - configMapRef:
                    name: daum
              args: [
                "python3", "batch.py",
                "--category", "daum",
                "--job_id", "sports"
              ]
