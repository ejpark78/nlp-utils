{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:40:43.257991Z",
     "start_time": "2020-01-15T00:40:43.249724Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:02:01.870405Z",
     "start_time": "2020-01-15T01:02:01.859944Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.mongodb_utils import MongoDBUtils\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:41:31.780564Z",
     "start_time": "2020-01-15T00:41:22.594383Z"
    }
   },
   "outputs": [],
   "source": [
    "db_info = {\n",
    "    'host': 'corpus',\n",
    "    'port': '27017',\n",
    "    'db_name': 'active_learning',\n",
    "    'collection': 'query-2019-09-11_124402',\n",
    "}\n",
    "\n",
    "mongo = MongoDBUtils()\n",
    "\n",
    "doc_list = mongo.get_all_documents(db_info=db_info, collection=db_info['collection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:41:32.358706Z",
     "start_time": "2020-01-15T00:41:31.781758Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(doc_list)\n",
    "\n",
    "print('{:,}'.format(len(df)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:41:40.771531Z",
     "start_time": "2020-01-15T00:41:40.713639Z"
    }
   },
   "outputs": [],
   "source": [
    "cleans = [doc for doc in doc_list if isinstance(doc['review'], str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:43:17.529012Z",
     "start_time": "2020-01-15T00:43:17.346124Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('.', '')\n",
    "    text = text.replace(',', '')\n",
    "    text = text.replace(';', '')\n",
    "    text = text.replace('~', '')\n",
    "    text = text.replace('+', '')\n",
    "    \n",
    "    return text\n",
    "\n",
    "texts = [clean_text(doc['review']) for doc in cleans]\n",
    "\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:44:07.740663Z",
     "start_time": "2020-01-15T00:43:29.035203Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=3, ngram_range=(2, 5), analyzer='char', max_features=500)\n",
    "\n",
    "X = cv.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:34:10.578850Z",
     "start_time": "2020-01-15T01:34:10.564379Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_wordcloud(data=None, backgroundcolor='black', width=800, height=600):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "    opt = {\n",
    "        'stopwords': STOPWORDS,\n",
    "        'background_color': backgroundcolor,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'font_path': '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n",
    "        'max_words': 20000,\n",
    "    }\n",
    "\n",
    "    wordcloud = WordCloud(**opt).generate(data)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:34:12.575699Z",
     "start_time": "2020-01-15T01:34:11.627419Z"
    }
   },
   "outputs": [],
   "source": [
    "display_wordcloud(' '.join(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T00:56:06.950362Z",
     "start_time": "2020-01-15T00:51:41.036339Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=100, n_init=1)\n",
    "\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T01:02:27.561557Z",
     "start_time": "2020-01-15T01:02:25.412640Z"
    }
   },
   "outputs": [],
   "source": [
    "def display():\n",
    "    import seaborn as sns\n",
    "\n",
    "    # 단어 수\n",
    "    num_words = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    # 중복을 제거한 단어 수\n",
    "    num_uniq_words = df['text'].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2)\n",
    "    fig.set_size_inches(18, 6)\n",
    "\n",
    "    print('리뷰 별 단어 평균값 :', num_words.mean())\n",
    "    print('리뷰 별 단어 중간값', num_words.median())\n",
    "    \n",
    "    sns.distplot(num_words, bins=100, ax=axes[0])\n",
    "    \n",
    "    axes[0].axvline(num_words.median(), linestyle='dashed')\n",
    "    axes[0].set_title('리뷰 별 단어 수 분포')\n",
    "\n",
    "    print('리뷰 별 고유 단어 평균값 :', num_uniq_words.mean())\n",
    "    print('리뷰 별 고유 단어 중간값', num_uniq_words.median())\n",
    "    \n",
    "    sns.distplot(num_uniq_words, bins=100, color='g', ax=axes[1])\n",
    "    \n",
    "    axes[1].axvline(num_uniq_words.median(), linestyle='dashed')\n",
    "    axes[1].set_title('리뷰 별 고유한 단어 수 분포')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T02:14:23.461209Z",
     "start_time": "2020-01-15T02:14:23.289769Z"
    }
   },
   "outputs": [],
   "source": [
    "index = {}\n",
    "result_list = []\n",
    "\n",
    "for i, t in enumerate(texts):\n",
    "    cls_id = kmeans.labels_[i]\n",
    "    \n",
    "    result_list.append({\n",
    "        'cls_id': cls_id,\n",
    "        'text': cleans[i]['review'],\n",
    "        'select': cleans[i]['select'],\n",
    "        'label': cleans[i]['label'],\n",
    "    })\n",
    "    \n",
    "    if cls_id not in index:\n",
    "        index[cls_id] = []\n",
    "        \n",
    "    index[cls_id].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T02:14:25.908601Z",
     "start_time": "2020-01-15T02:14:25.729077Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_list)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T02:14:26.099925Z",
     "start_time": "2020-01-15T02:14:26.056390Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('cls_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T02:18:08.331818Z",
     "start_time": "2020-01-15T02:18:08.290767Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(by=['select', 'label']).size().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T02:35:36.396897Z",
     "start_time": "2020-01-15T02:35:36.353691Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = -1\n",
    "\n",
    "df[ df['select'] == 'vote' ].sort_values(by=['cls_id', 'label'])[['cls_id', 'label', 'text', 'select']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://data-newbie.tistory.com/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=20)\n",
    "mu = nmf.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
