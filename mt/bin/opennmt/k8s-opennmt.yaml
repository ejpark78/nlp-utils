---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opennmt-api
  namespace: mtops
  labels:
    app: opennmt-api
spec:
  selector:
    matchLabels:
      app: opennmt-api
  replicas: 1
  template:
    metadata:
      labels:
        app: opennmt-api
    spec:
      restartPolicy: Always
      nodeSelector:
        kubernetes.io/hostname: "nlp-w13"
      hostAliases:
        - ip: "172.20.78.134"
          hostnames:
            - "mt.ncsoft.com"
        - ip: "172.20.79.243"
          hostnames:
            - "nlp.ncsoft.com"
        - ip: "172.20.93.112"
          hostnames:
            - "corpus.ncsoft.com"
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
      containers:
        - name: default
          image: corpus:5000/mtops/opennmt:latest
          imagePullPolicy: Always
          env:
            - name: PORT
              value: "80"
            - name: NVIDIA_VISIBLE_DEVICES
              value: "0"
            - name: CONFIG_HOST
              value: "https://corpus.ncsoft.com:9200"
            - name: CONFIG_INDEX
              value: "mt_pipeline-config"
            - name: CONFIG_DOC_ID
              value: "opennmt-dictionary_example"
            - name: CONFIG_USER_AUTH
              value: "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdXRoIjoiZWxhc3RpYzpubHBsYWIifQ.N1mOJmt5OBA7Ugi-xeBrY0GzFr79u7QQPHNf4EMxV_Q"
            - name: URL_ROOT
              value: "/nmt"
            - name: SERVER_CONFIG
              value: "bin/opennmt/server.json"
          workingDir: "/home/user"
          args: ["bin/opennmt/server.sh"]
          resources:
            limits:
              nvidia.com/gpu: 1
          ports:
            - containerPort: 80

---
apiVersion: v1
kind: Service
metadata:
  name: opennmt-api
  namespace: mtops
  labels:
    app: opennmt-api
spec:
  type: LoadBalancer
  selector:
    app: opennmt-api
  externalIPs:
    - 172.20.78.250
  ports:
    - protocol: TCP
      port: 61000
      targetPort: 80
